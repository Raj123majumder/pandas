{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mini-binary_tree.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOj7QLedu9PBwI4CqAcsRpQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raj123majumder/pandas/blob/master/mini_binary_tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXW9dY3_nQed",
        "outputId": "11c7a5b4-f7c8-4027-cea8-c943df67764f"
      },
      "source": [
        "###importing the required libraries\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger') "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsPNg8OeoRQ5"
      },
      "source": [
        "### importing the libraries\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "##ps = PorterStemmer()\n",
        "\n",
        "\n",
        "paragraph = \"\"\"Attention mechanism is one of the recent advancements in Deep learning especially for \n",
        "               Natural language processing tasks like Machine translation, Image Captioning, dialogue generation etc. It is a mechanism that \n",
        "               is developed to increase the performance of encoder decoder(seq2seq) RNN model. In this blog post I will try to explain the \n",
        "               attention mechanism for the text classification task.Attention is proposed as a solution to the limitation of the \n",
        "               Encoder-Decoder model which encodes the input sequence to one fixed length vector from which to decode the output at \n",
        "               each time step. This issue is believed to a problem when decoding long sequences because it make difficult for the neural network to cope \n",
        "               with long sentences, especially those that are longer than the sentences in the training corpus.In attention when the model is trying \n",
        "               to predict the next word it searches for a set of positions in a source sentence where the most relevant information is concentrated. \n",
        "               The model then predicts next word based on context vectors associated with these source positions and all the previous generated target \n",
        "               words.Instead of encoding the input sequence into a single fixed context vector, the attention model develops a context vector that is \n",
        "               filtered specifically for each output time step.Self-attention, also known as intra-attention, is an attention \n",
        "               mechanism relating different positions of a single sequence in order to compute a representation of the same sequence. \n",
        "               It has been shown to be very useful \n",
        "               in machine reading, abstractive summarization, or image description generation.Neural Machine Translation (NMT) achieved\n",
        "               state-of-the-art performances in large-scale translation tasks such as from English to French\n",
        "               (Luong et al., 2015) and English to German\n",
        "               (Jean et al., 2015). NMT is appealing since it requires minimal domain knowledge and is conceptually simple. \n",
        "               The model by Luong et al. (2015)\n",
        "               reads through all the source words until the end-ofsentence symbol <eos> is reached. It then starts emitting one \n",
        "               target word at a time, as illustrated in\n",
        "               Figure 1. NMT is often a large neural network that\n",
        "               is trained in an end-to-end fashion and has the ability to generalize well to very long word sequences.\n",
        "               This means the model does not have to explicitly\n",
        "               store gigantic phrase tables and language models\n",
        "               as in the case of standard MT; hence, NMT has\n",
        "               a small memory footprint. Lastly, implementing\n",
        "               NMT decoders is easy unlike the highly intricate\n",
        "               decoders in standard MT (Koehn et al., 2003).\n",
        "               In parallel, the concept of “attention” has\n",
        "               gained popularity recently in training neural networks, allowing models to learn alignments between different modalities, e.g., \n",
        "               between image\n",
        "               objects and agent actions in the dynamic control problem (Mnih et al., 2014), between speech\n",
        "               frames and text in the speech recognition task (?), or between visual features of a picture and\n",
        "               its text description in the image caption generation task (Xu et al., 2015). In the context of\n",
        "               NMT, Bahdanau et al. (2015) has successfully applied such attentional mechanism to jointly translate and align words. To the best of our knowledge, there has not been any other work exploring\n",
        "               the use of attention-based architectures for NMT.\n",
        "               In this work, we design, with simplicity and ef-\"\"\"\n",
        "\n",
        "wordnet=WordNetLemmatizer()\n",
        "sentences = nltk.sent_tokenize(paragraph)\n",
        "new_corpus = []\n",
        "for i in range(len(sentences)):\n",
        "    review = re.sub('[^a-zA-Z]', ' ', sentences[i])\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    review = [wordnet.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "    review = ' '.join(review)\n",
        "    new_corpus.append(review)\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OLYJY8vo0PY",
        "outputId": "57d150a3-7a3e-45fd-e916-438c5ac1049c"
      },
      "source": [
        "###the new corpus\n",
        "print(new_corpus)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['attention mechanism one recent advancement deep learning especially natural language processing task like machine translation image captioning dialogue generation etc', 'mechanism developed increase performance encoder decoder seq seq rnn model', 'blog post try explain attention mechanism text classification task attention proposed solution limitation encoder decoder model encodes input sequence one fixed length vector decode output time step', 'issue believed problem decoding long sequence make difficult neural network cope long sentence especially longer sentence training corpus attention model trying predict next word search set position source sentence relevant information concentrated', 'model predicts next word based context vector associated source position previous generated target word instead encoding input sequence single fixed context vector attention model develops context vector filtered specifically output time step self attention also known intra attention attention mechanism relating different position single sequence order compute representation sequence', 'shown useful machine reading abstractive summarization image description generation neural machine translation nmt achieved state art performance large scale translation task english french luong et al english german jean et al', 'nmt appealing since requires minimal domain knowledge conceptually simple', 'model luong et al', 'read source word end ofsentence symbol eos reached', 'start emitting one target word time illustrated figure', 'nmt often large neural network trained end end fashion ability generalize well long word sequence', 'mean model explicitly store gigantic phrase table language model case standard mt hence nmt small memory footprint', 'lastly implementing nmt decoder easy unlike highly intricate decoder standard mt koehn et al', 'parallel concept attention gained popularity recently training neural network allowing model learn alignment different modality e g image object agent action dynamic control problem mnih et al speech frame text speech recognition task', 'visual feature picture text description image caption generation task xu et al', 'context nmt bahdanau et al', 'successfully applied attentional mechanism jointly translate align word', 'best knowledge work exploring use attention based architecture nmt', 'work design simplicity ef']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFXSnU_3rr41"
      },
      "source": [
        "vocab_size = 1000"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xz8HAeir97v",
        "outputId": "9844acc8-db44-4722-ddfa-5bf4b688a550"
      },
      "source": [
        "onehot_repr=[one_hot(words,vocab_size)for words in new_corpus] \n",
        "print(onehot_repr)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[426, 103, 645, 874, 187, 251, 467, 932, 459, 853, 362, 127, 455, 276, 213, 687, 695, 664, 946, 216], [103, 339, 493, 903, 886, 217, 72, 72, 194, 568], [58, 195, 744, 574, 426, 103, 742, 663, 127, 426, 78, 941, 486, 886, 217, 568, 260, 258, 870, 645, 155, 85, 65, 601, 816, 462, 696], [11, 743, 58, 743, 936, 870, 194, 543, 584, 225, 356, 936, 24, 932, 837, 24, 275, 741, 426, 568, 511, 122, 91, 736, 208, 895, 757, 35, 24, 59, 845, 314], [568, 185, 91, 736, 365, 853, 65, 932, 35, 757, 611, 354, 230, 736, 923, 827, 258, 870, 421, 155, 853, 65, 426, 568, 591, 853, 65, 295, 745, 816, 462, 696, 33, 426, 812, 970, 412, 426, 426, 103, 928, 466, 757, 421, 870, 684, 797, 156, 870], [448, 794, 276, 262, 389, 800, 687, 219, 946, 584, 276, 213, 966, 421, 348, 34, 903, 376, 855, 213, 127, 846, 86, 507, 828, 852, 846, 364, 662, 828, 852], [966, 318, 434, 31, 26, 651, 611, 278, 7], [568, 507, 828, 852], [501, 35, 736, 844, 754, 436, 597, 623], [332, 232, 645, 230, 736, 462, 84, 844], [966, 601, 376, 584, 225, 39, 844, 844, 994, 508, 130, 287, 936, 736, 870], [606, 568, 998, 761, 315, 347, 225, 853, 568, 879, 909, 472, 932, 966, 936, 678, 771], [635, 87, 966, 217, 823, 174, 952, 970, 217, 909, 472, 162, 828, 852], [985, 707, 426, 689, 97, 862, 275, 584, 225, 956, 568, 648, 553, 466, 195, 262, 196, 687, 244, 978, 293, 324, 903, 58, 309, 828, 852, 998, 572, 742, 998, 153, 127], [251, 878, 70, 742, 219, 687, 634, 946, 127, 181, 828, 852], [853, 966, 651, 828, 852], [618, 357, 731, 103, 179, 783, 382, 736], [186, 611, 250, 804, 894, 426, 365, 147, 966], [250, 600, 479, 895]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QB2XG93YsE18",
        "outputId": "99a4d6c1-d27e-4be8-a64d-d7f39e58b8e2"
      },
      "source": [
        "###the max length\n",
        "max_length = max(len(l) for l in onehot_repr)\n",
        "print(max_length)\n",
        "new = [len(l) for l in onehot_repr]\n",
        "print(new)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49\n",
            "[20, 10, 27, 32, 49, 31, 9, 4, 8, 8, 15, 17, 14, 33, 12, 5, 8, 9, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXmuL3iBsdIh",
        "outputId": "6ccff890-fc37-4949-8f78-49bca6988fc2"
      },
      "source": [
        "sent_length=40\n",
        "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
        "print(embedded_docs)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0 426 103 645 874 187 251 467 932 459 853 362 127 455 276 213 687\n",
            "  695 664 946 216]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0 103 339 493 903 886 217\n",
            "   72  72 194 568]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  58 195 744 574 426\n",
            "  103 742 663 127 426  78 941 486 886 217 568 260 258 870 645 155  85  65\n",
            "  601 816 462 696]\n",
            " [  0   0   0   0   0   0   0   0  11 743  58 743 936 870 194 543 584 225\n",
            "  356 936  24 932 837  24 275 741 426 568 511 122  91 736 208 895 757  35\n",
            "   24  59 845 314]\n",
            " [757 611 354 230 736 923 827 258 870 421 155 853  65 426 568 591 853  65\n",
            "  295 745 816 462 696  33 426 812 970 412 426 426 103 928 466 757 421 870\n",
            "  684 797 156 870]\n",
            " [  0   0   0   0   0   0   0   0   0 448 794 276 262 389 800 687 219 946\n",
            "  584 276 213 966 421 348  34 903 376 855 213 127 846  86 507 828 852 846\n",
            "  364 662 828 852]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0 966 318 434  31  26\n",
            "  651 611 278   7]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  568 507 828 852]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0 501  35 736 844\n",
            "  754 436 597 623]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0 332 232 645 230\n",
            "  736 462  84 844]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0 966 601 376 584 225  39 844 844 994 508 130\n",
            "  287 936 736 870]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0 606 568 998 761 315 347 225 853 568 879 909 472 932\n",
            "  966 936 678 771]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0 635  87 966 217 823 174 952 970 217 909\n",
            "  472 162 828 852]\n",
            " [  0   0   0   0   0   0   0 985 707 426 689  97 862 275 584 225 956 568\n",
            "  648 553 466 195 262 196 687 244 978 293 324 903  58 309 828 852 998 572\n",
            "  742 998 153 127]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0 251 878  70 742 219 687 634 946\n",
            "  127 181 828 852]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 853\n",
            "  966 651 828 852]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0 618 357 731 103\n",
            "  179 783 382 736]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0 186 611 250 804 894\n",
            "  426 365 147 966]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  250 600 479 895]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20Gj5huPueIs"
      },
      "source": [
        "class Node:\n",
        " \n",
        "    #create a new node\n",
        "    def __init__(self, key):\n",
        "\n",
        "        self.data = key\n",
        "        self.left = None\n",
        "        self.right = None\n",
        " \n",
        "def insertLevelOrder(lists, root, i, n):\n",
        "  if i < n:\n",
        "    temp = Node(lists[i])\n",
        "    root = temp\n",
        "    root.left = insertLevelOrder(lists, root.left,2 * i + 1, n)\n",
        "    root.right = insertLevelOrder(lists, root.right,2 * i + 2, n)\n",
        "  return root\n",
        "\n",
        " \n",
        "# Function to  print level order traversal of tree\n",
        "def printLevelOrder(root):\n",
        "  h = height(root)\n",
        "  for i in range(1, h+1):\n",
        "    printCurrentLevel(root, i)\n",
        " \n",
        " \n",
        "# Print nodes at a current level\n",
        "def printCurrentLevel(root, level):\n",
        "  if root is None:\n",
        "    return\n",
        "  if level == 1:\n",
        "    print(root.data, end=\" \")\n",
        "  elif level > 1:\n",
        "        printCurrentLevel(root.left, level-1)\n",
        "        printCurrentLevel(root.right, level-1)\n",
        " \n",
        "###computing the hieght of the tree\n",
        " \n",
        "def height(node):\n",
        "  if node is None:\n",
        "    return 0\n",
        "  else:\n",
        "    # Compute the height of each subtree\n",
        "    lheight = height(node.left)\n",
        "    rheight = height(node.right)\n",
        " \n",
        "    # Use the larger one\n",
        "    if lheight > rheight:\n",
        "      return lheight+1\n",
        "    else:\n",
        "      return rheight+1\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgo4mk2Wx43-",
        "outputId": "1e13edc0-c836-4e14-de8f-d3a24234fd6d"
      },
      "source": [
        "###contructing the binary tree \n",
        "\n",
        "for lists in embedded_docs:\n",
        "  new_len = len(lists)\n",
        "  root = None\n",
        "  root = insertLevelOrder(lists, root, 0, new_len)\n",
        "  printLevelOrder(root)\n",
        "  print('\\n')\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 426 103 645 874 187 251 467 932 459 853 362 127 455 276 213 687 695 664 946 216 \n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 103 339 493 903 886 217 72 72 194 568 \n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0 0 0 0 58 195 744 574 426 103 742 663 127 426 78 941 486 886 217 568 260 258 870 645 155 85 65 601 816 462 696 \n",
            "\n",
            "0 0 0 0 0 0 0 0 11 743 58 743 936 870 194 543 584 225 356 936 24 932 837 24 275 741 426 568 511 122 91 736 208 895 757 35 24 59 845 314 \n",
            "\n",
            "757 611 354 230 736 923 827 258 870 421 155 853 65 426 568 591 853 65 295 745 816 462 696 33 426 812 970 412 426 426 103 928 466 757 421 870 684 797 156 870 \n",
            "\n",
            "0 0 0 0 0 0 0 0 0 448 794 276 262 389 800 687 219 946 584 276 213 966 421 348 34 903 376 855 213 127 846 86 507 828 852 846 364 662 828 852 \n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 966 318 434 31 26 651 611 278 7 \n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 568 507 828 852 \n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 501 35 736 844 754 436 597 623 \n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 332 232 645 230 736 462 84 844 \n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 966 601 376 584 225 39 844 844 994 508 130 287 936 736 870 \n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 606 568 998 761 315 347 225 853 568 879 909 472 932 966 936 678 771 \n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 635 87 966 217 823 174 952 970 217 909 472 162 828 852 \n",
            "\n",
            "0 0 0 0 0 0 0 985 707 426 689 97 862 275 584 225 956 568 648 553 466 195 262 196 687 244 978 293 324 903 58 309 828 852 998 572 742 998 153 127 \n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 251 878 70 742 219 687 634 946 127 181 828 852 \n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 853 966 651 828 852 \n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 618 357 731 103 179 783 382 736 \n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 186 611 250 804 894 426 365 147 966 \n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 250 600 479 895 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVlTHHYS26rH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}